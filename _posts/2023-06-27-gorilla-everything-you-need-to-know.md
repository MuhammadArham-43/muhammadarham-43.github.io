---
layout: post
title: "Gorilla: Everything You Need to Know"
date: 2023-06-27 22:01:52 +0000
canonical_url: https://pub.towardsai.net/gorilla-everything-you-need-to-know-c07d7eb7956f?source=rss-8c8a65726e4c------2
link: https://pub.towardsai.net/gorilla-everything-you-need-to-know-c07d7eb7956f?source=rss-8c8a65726e4c------2
categories: [medium]
---

<h4>This article introduces Gorilla; UC Berkeley, and Microsoft’s API support for Large Language Models.</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*TzRhcyx_SB147pJ8" /><figcaption>Image by Author</figcaption></figure><h3>Introduction</h3><p>LLMs suffer from outdated information and they require re-training to keep up-to-date with recent changes. With limited context and weights, LLMs cannot store data for accurate responses. Therefore, LLMs are augmented by the use of numerous tools and plugins that use external APIs for better answers.</p><p>Gorilla introduces self-instruct fine-tuning and retrieval training on a large corpus of APIs that provides better results than leading LLMs, including but not limited to ChatGPT4 and Claude.</p><h3>Dataset</h3><p>The authors created <strong>APIBench, </strong>an exhaustive set of API corpus, scraped from the three major model hubs.</p><ul><li><strong>TorchHub</strong>: 94 API calls</li><li><strong>TensorHub</strong>:696 API calls</li><li><strong>HuggingFace</strong>: Chose only the 20 most downloaded models totaling 925 API calls.</li></ul><p>Then using Self-Instruct, the authors used GPT 4 to generate realistic prompts that use the APIs and constructed 10 different instruction-API pairs to finetune LLMs.</p><h3>Finetuning</h3><p>Gorilla is a LLaMA-7B fine-tuned model on the APIBench dataset. The authors use a chat-style training where each API call is used, similar to a real-world conversation between a user and a chatbot. The LLaMA model is then finetuned <em>with and without a retriever.</em></p><h4>API Call with Constraints</h4><p>Consider the following prompt:</p><blockquote>Invoke an image classification model that uses less than 10M parameters, but maintains an ImageNet accuracy of at least 70%</blockquote><p>LLMs face issues when generating responses for such prompts, as the user adds constraints on an API call and its associated parameters.</p><h4>Retreiver-Aware Training</h4><p>In certain scenarios, the model is constrained by a specific API call or documentation that can degrade responses provided by the LLMs. Consider the following prompt:</p><blockquote>“Use this API documentation for reference: &lt;retrieved_API_doc_JSON&gt;”</blockquote><p>During finetuning, Gorilla aims to parse the second half to fetch the required API specification to answer the first part of the question.</p><h3>Inference</h3><p>Gorilla can be used in two different modes, similar to the two methods mentioned above.</p><p>A user provides a prompt in natural language, and it is parsed by Gorilla in two ways. <strong>Zero-shot </strong>passes the same prompt with no additions to finetuned Gorilla LLM, which returns an API response. In <strong>Retrieval-mode, </strong>Gorilla uses GPT-Index or BM25 to first retrieve the most appropriate API documentation, which is added to the user prompt. The message <em>Use this API documentation for reference:</em> is concatenated with the user prompt before sending it to Gorilla LLM.</p><p>The methodology is summarized by the following image:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/970/0*yrJv6p1ERYuX4qxl" /><figcaption>Image from <a href="https://arxiv.org/pdf/2305.15334v1.pdf">Paper</a></figcaption></figure><p>The authors used the large API data corpus to generate 16450 prompts, and response pairs generated using self-instruct. These were used to finetune the Gorilla LLM. At inference time, the image highlights the two inference methods, <strong>Zero-shot, </strong>and <strong>Information retrieval </strong>methods. When using zero-shot, the prompt is passed as is to the Gorilla LLM without any preprocessing. When using the information retrieval method, the natural language prompt is sent to a retriever that compares the user prompt with an existing API database. Relevant API documentation is returned and concatenated with the user prompt before sending it to Gorilla LLM.</p><h3>Results</h3><p>The image from the paper highlights the improvements of Gorilla over other LLM models.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/938/0*Wsvj8kc16-dl1HfD" /><figcaption>Image from <a href="https://arxiv.org/pdf/2305.15334v1.pdf">Paper</a></figcaption></figure><p>The paper summarizes the results of evaluating Gorilla on the collected dataset with different retrieval methods. The model performs better than other LLMs when queried with API-specific prompts. The graphical illustration highlights such results:</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/944/0*qPBDdcjq6NOhCccw" /><figcaption>Image from <a href="https://arxiv.org/pdf/2305.15334v1.pdf">Paper</a></figcaption></figure><h3>Benefits of Gorilla LLM:</h3><h4>Reduced Hallucinations</h4><p>Hallucinations refer to code generated with the wrong API or an API that does not exist. This can lead to runtime errors and non-functional code. Gorilla is specifically finetuned on a large corpus of API calls reducing the chances of hallucination errors. An example is provided in the results section of this article.</p><h4>Improved Code Generation</h4><p>With more structured responses that use the most up-to-date API documentation fetched at runtime, the responses are better suited for code generation. This can save a lot of cost and time in debugging generated code, as the responses are dependable.</p><h3>Usage</h3><p>The code is open-source and can be accessed on GitHub. For inference, the Gorilla can be accessed using the provided <a href="https://colab.research.google.com/drive/1DEBPsccVLF_aUnmD0FwPeHFrtdC0QIUP?usp=sharing">Colab notebook</a> or accessed with a Command Line Interface through code.</p><p>First, create a new environment and install all dependencies.</p><pre>conda create -n gorilla python=3.10<br>conda activate gorilla<br>pip install -r requirements.txt</pre><p>Finetuned delta weights for Gorilla are available on <a href="https://huggingface.co/gorilla-llm/gorilla-7b-hf-delta-v0">HuggingFace</a>. Original LLaMA weights are available <a href="https://huggingface.co/docs/transformers/main/model_doc/llama">here</a>. After downloading weights, apply the weights to the original LLaMA model using the following code:</p><pre>python3 apply_delta.py <br> - base-model-path path/to/hf_llama/ <br> - target-model-path path/to/gorilla-7b-hf-v0 <br> - delta-path path/to/models - gorilla-llm - gorilla-7b-hf-delta-v0</pre><p>The model can then be run with the given command:</p><pre>python3 serve/gorilla_cli.py - model-path path/to/gorilla-7b-{hf,th,tf}-v0</pre><h3>Conclusion</h3><p>The article introduced Gorilla LLM, the LLaMA model specifically finetuned for API calls. It provides better responses than GPT-4 on all 3 datasets collected and is better suited to adapt to run-time API usage changes.</p><p>The correct usage of Gorilla can improve the performance of LLMs using a wide variety of tools and plugins.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=c07d7eb7956f" width="1" height="1" alt=""><hr><p><a href="https://pub.towardsai.net/gorilla-everything-you-need-to-know-c07d7eb7956f">Gorilla: Everything You Need to Know</a> was originally published in <a href="https://pub.towardsai.net">Towards AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>