---
layout: post
title: "AlexNet: Implementation from Scratch"
date: 2023-06-27 00:01:57 +0000
canonical_url: https://pub.towardsai.net/alexnet-implementation-from-scratch-667063ab5b44?source=rss-8c8a65726e4c------2
link: https://pub.towardsai.net/alexnet-implementation-from-scratch-667063ab5b44?source=rss-8c8a65726e4c------2
categories: [medium]
---

<h4>A PyTorch series for people starting with Deep Learning. Following an implementation-based approach of various well-known architectures.</h4><figure><img alt="" src="https://cdn-images-1.medium.com/max/948/0*J9ggCiGMf_8-tUuM" /><figcaption>Image from <a href="https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">Paper</a></figcaption></figure><h3>Introduction</h3><p>The Alexnet architecture was a breakthrough at the time of its publication, achieving minimal loss on the ImageNet classification task. It uses sequential convolutional blocks with some fully connected layers for the classification task. In this article, we understand the architecture and code it in PyTorch.</p><h3>Architecture</h3><p>The flowchart shows the basic outline of the process.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1021/0*A_cE0jMbGDuPvPMm" /><figcaption>Image by Author</figcaption></figure><p>The input image is of size 227, width and height with 3 color channels i.e., RGB. They are passed through a series of Convolutional blocks consisting of Convolutional, ReLU, Normalization, and Pooling layers. The output is then flattened to a one-dimensional array and passed through several dense layers. The result is a one-dimensional array, with the size of the vector representing the total number of classes.</p><p><strong>The exact dimensions and details are extracted directly from the Alex Net paper.</strong></p><p>The pooling layers reduce the input size and the convolutional filters vary the total channels in the input. The output of the convolutional blocks is a (256,6,6) tensor that is flattened to a single dimension, i.e. 256x6x6 dimensional vector that equals 9216. The vector is passed through two dense layers consisting of 4096 neurons. The last fully connected layer reduces the total output neurons to the number of possible classes.</p><h4>Convolutional Layers</h4><p>If we look into the convolutional layers inside, there are 5 similar blocks, each composed of similar layers.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*brBb4tLoG-VdCOsr" /><figcaption>Image by Author</figcaption></figure><p>The input to the first block is an RGB image with 3 color channels. Each block processes the input and passes the output to the next block in a sequential manner. The output sizes of each block are shown in the image.</p><h4>Convolutional Block</h4><p>The flowchart shows the layers each block is composed of.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/926/0*LwDFnvWXywtlo4GO" /><figcaption>Image by Author</figcaption></figure><p>Each block, except 3 and 4 has the above structure. Layers 3 and 4 have no normalization and pooling layers at the end.</p><h4>Convolutional Sizes</h4><p>Each block has different sizes of convolutional layers. The table summarizes the sizes used in the paper. Each convolutional layer uses a ReLU activation that is shown explicitly.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/646/1*oRtp1_YlPo-Kdd1PGR69Hg.png" /></figure><h4>Normalization</h4><p>The paper uses LocalResponseNormalization that helps generalized, and as per the paper, improved performance on the classification task. For normalization hyperparameters, they use the following values.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/643/1*zKv_edNVCIg803hNiFx0zg.png" /></figure><p>Refer to the <a href="https://pytorch.org/docs/stable/generated/torch.nn.LocalResponseNorm.html">documentation</a> to learn about what these parameters represent.</p><h3>Pooling Layers</h3><p>The paper proposes to use overlapping pooling where the stride is different from the kernel size. Experimentally, the overlapping pooling reduced the error rates relative to the non-overlapping pooling with the same stride and kernel. Therefore, all pooling layers in the convolutional blocks use stride 2 and kernel size 3.</p><h3>Implementation</h3><p>We start our implementation from the convolutional block structure, which is generalizable to all of the 5 blocks. This can allow modularity, and allow reuse when implementing the complete Alex Net architecture. This reduces code duplication.</p><pre>class AlexNetBlock(nn.Module):<br> def __init__(<br>     self,<br>     in_channels,<br>     out_channels,<br>     kernel_size,<br>     stride,<br>     padding,<br>     pool_and_norm: bool = True<br> ) -&gt; None:<br><br>     super(AlexNetBlock, self).__init__()<br>     self.conv_layer = nn.Conv2d(<br>         in_channels, out_channels, kernel_size, stride, padding)<br>     self.relu = nn.ReLU()<br><br>     self.pool_and_norm = pool_and_norm<br>     if pool_and_norm:<br>         self.norm_layer = nn.LocalResponseNorm(<br>             size=5, alpha=0.0001, beta=0.75, k=2)<br>         self.pool_layer = nn.MaxPool2d(stride=2, kernel_size=3)<br><br> def forward(self, x):<br>     x = self.conv_layer(x)<br>     x = self.relu(x)<br><br>     if self.pool_and_norm:<br>         x = self.norm_layer(x)<br>         x = self.pool_layer(x)<br>     return x</pre><p>The code is self-explanatory, where we receive parameters for the convolutional layer. In addition, we use a pool_and_norm boolean value that will be set to False for block 3 and block 4. The above block can be used in the complete Alex Net architecture.</p><p>The below code shows the complete Alex Net model, that uses the above block.</p><pre>class AlexNet(nn.Module):<br> def __init__(self, num_classes, in_channels) -&gt; None:<br>     super(AlexNet, self).__init__()<br><br>     self.block1 = AlexNetBlock(<br>         in_channels, 96, 11, 4, 0, pool_and_norm=True)<br>     self.block2 = AlexNetBlock(96, 256, 5, 1, 2, pool_and_norm=True)<br>     self.block3 = AlexNetBlock(256, 384, 3, 1, 1, pool_and_norm=False)<br>     self.block4 = AlexNetBlock(384, 384, 3, 1, 1, pool_and_norm=False)<br>     self.block5 = AlexNetBlock(384, 256, 3, 1, 1, pool_and_norm=True)<br><br>     self.flatten = nn.Flatten()<br>     self.fc1 = nn.Linear(256 * 6 * 6, 4096)<br>     self.dropout1 = nn.Dropout(0.5)<br>     self.fc2 = nn.Linear(4096, 4096)<br>     self.dropout2 = nn.Dropout(0.5)<br>     self.classification_layer = nn.Linear(4096, num_classes)<br><br> def forward(self, x):<br>     x = self.block1(x)<br>     x = self.block2(x)<br>     x = self.block3(x)<br>     x = self.block4(x)<br>     x = self.block5(x)<br><br>     x = self.flatten(x)<br>     x = self.fc1(x)<br>     x = self.dropout1(x)<br>     x = self.fc2(x)<br>     x = self.dropout2(x)<br>     x = self.classification_layer(x)<br>     return x</pre><p>As per the flowchart, we create 5 Alex Net blocks with the configuration described. We then sequentially pass the input through all the layers, till we achieve a one-dimensional array representing the probability of each possible class.</p><p>For this specific instance, we need two initialization parameters for AlexNet. One is input channels that are by default three for RGB images. The second is the total number of classes that defines our output size. In the paper, the value used was 1000 for the Image Net task. For my implementation, I use the CIFAR-10 dataset so I set it to ten.</p><p>The below image summarizes the Alex Net architecture.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/867/0*DP1ba3sRsWLK0TqL" /><figcaption>Image by Author</figcaption></figure><h3>Conclusion</h3><p>The above architecture can be trained for a classification task from scratch. I trained it for the CIFAR-10 dataset for ten epochs. The below graph shows the loss progression.</p><figure><img alt="" src="https://cdn-images-1.medium.com/max/330/0*jiiK2eIQCNqG-SE6" /><figcaption>Image by Author</figcaption></figure><p>For just ten epochs, the Cross-Entropy Loss is reducing gradually, and we can do well for simple classification tasks.</p><p>The article only shows code snippets for understanding. For complete implementation and training code, refer to my <a href="https://github.com/MuhammadArham-43/PytorchImplementations.git">GitHub repo</a>. For a detailed understanding of the architecture, consider reading the <a href="https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf">paper</a>.</p><img src="https://medium.com/_/stat?event=post.clientViewed&referrerSource=full_rss&postId=667063ab5b44" width="1" height="1" alt=""><hr><p><a href="https://pub.towardsai.net/alexnet-implementation-from-scratch-667063ab5b44">AlexNet: Implementation from Scratch</a> was originally published in <a href="https://pub.towardsai.net">Towards AI</a> on Medium, where people are continuing the conversation by highlighting and responding to this story.</p>